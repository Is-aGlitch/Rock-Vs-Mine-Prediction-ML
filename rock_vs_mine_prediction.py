# -*- coding: utf-8 -*-
"""Rock Vs Mine Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R8hb5FXlmuhPPWrdwcFGqbUw6sE1afna
"""



"""Importing the dependencies"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score



"""Data collection and data processing"""

#Loading a dataset to a pandas dataframe
#header = None is because we dont have any headers in our data file so we need to specify it
sonar_data = pd.read_csv('/content/Copy of sonar data.csv', header = None)

#Gives the first five rows of our dataset
sonar_data.head()

#Number of rows and columns
sonar_data.shape

#To obtain statistical data mean median etc
sonar_data.describe()

#To check how many rock and how many mine data are there, 60 tells the data is in 60th row
sonar_data[60].value_counts()

"""M --> Mine
R --> Rock
"""

#Grouping of data based on various factors
sonar_data.groupby(60).mean() #give the mean of all 60 columns og M and R seperately

#Seperating Data and Labels
X = sonar_data.drop(columns = 60, axis =1)
Y = sonar_data[60]

print(X)
print(Y)

"""Training and Test data"""

#test_size = 0.1 means 10% of data will be test data
#stratify =  Y means our data will be split on the basis of Y (Rock and mine)
#ransom_state is to split the data in  a particular order

X_train, X_test, Y_train, Y_test =  train_test_split(X, Y, test_size = 0.1, stratify = Y, random_state = 1)

print(X.shape, X_train.shape, X_test.shape)

"""Model Training --> Logistic Regression Model"""

print(X_train)
print(Y_train)

model =  LogisticRegression() #It will load the logistic regression function into model variable

#training the Logistic Regression model with training data
#The fit() method takes the training data as arguments
model.fit(X_train, Y_train)

"""Model Evaluation"""

#accuracy on the training data
#Y_train is the real data label we are comparing our accuracy with it
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

print('Accuracy on training data: ', training_data_accuracy)

X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print('Accuracy on test data: ', test_data_accuracy)

"""Making a predictive system"""

input_data = (0.0039,0.0063,0.0152,0.0336,0.0310,0.0284,0.0396,0.0272,0.0323,0.0452,0.0492,0.0996,0.1424,0.1194,0.0628,0.0907,0.1177,0.1429,0.1223,0.1104,0.1847,0.3715,0.4382,0.5707,0.6654,0.7476,0.7654,0.8555,0.9720,0.9221,0.7502,0.7209,0.7757,0.6055,0.5021,0.4499,0.3947,0.4281,0.4427,0.3749,0.1972,0.0511,0.0793,0.1269,0.1533,0.0690,0.0402,0.0534,0.0228,0.0073,0.0062,0.0062,0.0120,0.0052,0.0056,0.0093,0.0042,0.0003,0.0053,0.0036)
#changing the input data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

#reshape the np array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if(prediction[0] == 'R'):
  print('The object is a Rock')
else:
  print('The object is a Mine')